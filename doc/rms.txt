The momentum method

equations:
v(t) = a*(v(t-1)) - epsilon*grad(t)
delta[w(t)] = v(t) : the weight change is equal to the current velocity
            = a*v(t-1) - epsilon*grad(t)
            = a*w(t-1) - epsilon*grad(t)

*Behavior of the momentum method
if the error sufface is a tilted plan, the ball reaches a terminal velocity.
(if the momentum is close to 1, this is much faster than simple gradient descent)
At the begining of learning there may be very large gradients.
- So it pays to use small momentum (eg 0.5)
- Once the large grdients have disappeared and the weights are stuck in a ravine the
momentum can be smooth ly raised to its final value (eg 0.9 or even 0.99)
This allow to learn at a rate that would cause divergent oscillations without the
momentum.
v(inf) =  (1/1-a) * (-epsilon*grad)

** A better type of momentum (Nesterov 1983)
First make a big jump in the direction of the previous accumulated gradient.
Then measure the gradient where you end up and make a correction
(its better to correct a mistake after you have made it!!!)


** A separate, adaptive learning rate for each connection
In a multilayer net, the appropriate learning rates can vary widely between weights:
- The magnitudes of the gradients are oftern very different for different layers,
especially if the initial weights are small.
- The fan-in of a unit determines the size of the "overshoot" effects cause by stimultaneously
changing many of the incoming weights of a unit to correct the same error.

* One way to determine the individual learning rates
- Start with a loval gain of 1 for every weight.
- Increase the local gain if the gradient for that weight does not change sign.
- Use small additive increases and multiplicative decrease (for mini-batch)
    + This ensures that big gains decay rapidly when oscillations start.
    + If the gradient is totally random the gain will hover around 1 when we increases
    by plus delta half the time and decrease by times 1-delta half the time.

** RMSprop: Divide the gradient by a running avearage of its recent magnitudes
*Rprop: Using only the sign of the gradient
The mignitude of the grdient can be very different for different wieghts and can change
during learning.
- This makes it hard to choose a single global learning rate.
For full batch learning, we can deal with this variation by only using the sign of the
gradient.
- The weight updates are all of the same magnitude.
- This escapes from plateaus with tiny gradient quickly.
Rprop: This combines the idea of only using the gradient with the idea of adapting the
step size separately for each weight.
- Increase the step size for a weight multiplicatively(eg times 1.2) if the signs of
its last two gradientts agree.
- Otherwise decrease the step size multiplicatively(egtime0.5)
- Limit the step sizes to be less than 50 and more than a million (Mike Shuster's advice)/

* Why rprop does not work with mini-batches
The idea behind stochastic gradient descent is that when the lr is small, it averages the
gradientns over the successive mini-batches
- Consider a weight that gets a gradient of +0.1 on nine mini-batches and a gradient of
-0.9 on the tenth mini-batch.
- We want this weight to stay rougly where it is.
rprop would increment the weight niine times and decrement it once by the same amount
- So the weight would grow a lot.
Is there a way to combine:
- The robustnees of rprop.
- The efficiency of mini-batches
- The effective averaging of gradients over mini-batches.

*RmsProp: A mini-batch version of rprop
