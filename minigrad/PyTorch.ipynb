{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdee2f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/letunglam/Projects/deep-learning-training/minigrad/datasets\n",
      "/Users/letunglam/Projects/deep-learning-training/minigrad\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%cd datasets\n",
    "!bash get_datasets.sh\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728cc169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd45b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening:  tensor([[[[ 0,  1],\n",
      "          [ 2,  3],\n",
      "          [ 4,  5]]],\n",
      "\n",
      "\n",
      "        [[[ 6,  7],\n",
      "          [ 8,  9],\n",
      "          [10, 11]]]])\n",
      "after flatenning:  tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read\n",
    "    return x.view(N, -1)\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('after flatenning: ', flatten(x))\n",
    "\n",
    "test_flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b38c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def two_layer_fc(x, params):\n",
    "    \"\"\"\n",
    "    A fully-connected NN,\n",
    "    \"\"\"\n",
    "\n",
    "    x = flatten(x)\n",
    "\n",
    "    w1, w2 = params\n",
    "\n",
    "    x = F.relu(x.mm(w1))\n",
    "    x = x.mm(w2)\n",
    "    return x\n",
    "\n",
    "def two_layer_fc_test():\n",
    "    hidden_layer_size = 42\n",
    "    x = torch.zeros((64, 50), dtype=dtype)\n",
    "    w1 = torch.zeros((50, hidden_layer_size), dtype=dtype)\n",
    "    w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype)\n",
    "    scores = two_layer_fc(x, [w1, w2])\n",
    "    print(scores.size())\n",
    "\n",
    "two_layer_fc_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57c11122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_convnet(x, params):\n",
    "    \"\"\"\n",
    "    Performs the forward pass of a three-layer convolutional network with the\n",
    "    architecture defined above.\n",
    "\n",
    "    Inputs:\n",
    "    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images\n",
    "    - params: A list of PyTorch Tensors giving the weights and biases for the\n",
    "      network; should contain the following:\n",
    "      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n",
    "        for the first convolutional layer\n",
    "      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n",
    "        convolutional layer\n",
    "      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n",
    "        weights for the second convolutional layer\n",
    "      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n",
    "        convolutional layer\n",
    "      - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n",
    "        figure out what the shape should be?\n",
    "      - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n",
    "        figure out what the shape should be?\n",
    "\n",
    "    Returns:\n",
    "    - scores: PyTorch Tensor of shape (N, C) giving classification scores for x\n",
    "    \"\"\"\n",
    "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
    "    x = F.relu(F.conv2d(x, conv_w1, conv_b1, padding=2))\n",
    "    x = F.relu(F.conv2d(x, conv_w2, conv_b2, padding=1))\n",
    "    scores = flatten(x).mm(fc_w) + fc_b\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8a49965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "def three_layer_convnet_test():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)\n",
    "\n",
    "    conv_w1 = torch.zeros((6, 3, 5, 5),dtype=dtype)\n",
    "    conv_b1 = torch.zeros((6,))\n",
    "    conv_w2 = torch.zeros((9, 6, 3, 3))\n",
    "    conv_b2 = torch.zeros((9,))\n",
    "\n",
    "    fc_w = torch.zeros((9*32*32, 10))\n",
    "    fc_b = torch.zeros(10)\n",
    "\n",
    "    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n",
    "    print(scores.size())\n",
    "three_layer_convnet_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd94ea14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2822,  0.3512,  1.7735, -0.2328, -1.7790],\n",
       "        [ 0.5571,  1.4962,  0.4925, -0.5720,  1.1564],\n",
       "        [ 0.8788, -0.0739,  1.3372,  0.6263,  0.5293]], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_weight(shape):\n",
    "    \"\"\"\n",
    "    Create random Tensors for weights; setting requires_grad=True means that we\n",
    "    want to compute gradients for these Tensors during the backward pass.\n",
    "    We use Kaiming normalization: sqrt(2 / fan_in)\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:])\n",
    "\n",
    "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "    w.requires_grad= True\n",
    "    return w\n",
    "\n",
    "def zero_weight(shape):\n",
    "    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "random_weight((3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bb3cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part2(loader, model_fn, params):\n",
    "    \"\"\"\n",
    "    Check the accuracy of a classification model.\n",
    "\n",
    "    Inputs:\n",
    "    - loader: A DataLoader for the data split we want to check\n",
    "    - model_fn: A function that performs the forward pass of the model,\n",
    "      with the signature scores = model_fn(x, params)\n",
    "    - params: List of PyTorch Tensors giving parameters of the model\n",
    "\n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    split = 'val' if loader.dataset.train else 'test'\n",
    "    print('Checking accuracy on the %s set' % split)\n",
    "    num_correct, num_samples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.int64)\n",
    "            scores = model_fn(x, params)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds==y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cc9f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part2(model_fn, params, learning_rate):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10.\n",
    "\n",
    "    Inputs:\n",
    "    - model_fn: A Python function that performs the forward pass of the model.\n",
    "      It should have the signature scores = model_fn(x, params) where x is a\n",
    "      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n",
    "      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n",
    "      scores for the elements in x.\n",
    "    - params: List of PyTorch Tensors giving weights for the model\n",
    "    - learning_rate: Python scalar giving the learning rate to use for SGD\n",
    "\n",
    "    Returns: Nothing\n",
    "    \"\"\"\n",
    "    for t, (x, y) in enumerate(loader_train):\n",
    "        x = x.to(device=device, dtype=dtype)\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "        scores = model_fn(x, params)\n",
    "        loss = F.cross_entropy(scores, y)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for w in params:\n",
    "                w -= learning_rate * w.grad\n",
    "\n",
    "                w.grad.zero_()\n",
    "\n",
    "        if t % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "            check_accuracy_part2(loader_val, model_fn, params)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f96b34d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.3838\n",
      "Checking accuracy on the val set\n",
      "Got 108 / 1000 correct (0.11%)\n",
      "\n",
      "Iteration 100, loss = 2.3637\n",
      "Checking accuracy on the val set\n",
      "Got 360 / 1000 correct (0.36%)\n",
      "\n",
      "Iteration 200, loss = 1.5350\n",
      "Checking accuracy on the val set\n",
      "Got 371 / 1000 correct (0.37%)\n",
      "\n",
      "Iteration 300, loss = 2.0431\n",
      "Checking accuracy on the val set\n",
      "Got 336 / 1000 correct (0.34%)\n",
      "\n",
      "Iteration 400, loss = 1.7830\n",
      "Checking accuracy on the val set\n",
      "Got 406 / 1000 correct (0.41%)\n",
      "\n",
      "Iteration 500, loss = 1.9439\n",
      "Checking accuracy on the val set\n",
      "Got 424 / 1000 correct (0.42%)\n",
      "\n",
      "Iteration 600, loss = 1.8237\n",
      "Checking accuracy on the val set\n",
      "Got 399 / 1000 correct (0.40%)\n",
      "\n",
      "Iteration 700, loss = 2.1525\n",
      "Checking accuracy on the val set\n",
      "Got 433 / 1000 correct (0.43%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "w1 = random_weight((3 * 32* 32, hidden_layer_size))\n",
    "w2 = random_weight((hidden_layer_size, 10))\n",
    "\n",
    "train_part2(two_layer_fc, [w1, w2], learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe35c0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 4.0382\n",
      "Checking accuracy on the val set\n",
      "Got 86 / 1000 correct (0.09%)\n",
      "\n",
      "Iteration 100, loss = 1.8815\n",
      "Checking accuracy on the val set\n",
      "Got 373 / 1000 correct (0.37%)\n",
      "\n",
      "Iteration 200, loss = 1.5817\n",
      "Checking accuracy on the val set\n",
      "Got 396 / 1000 correct (0.40%)\n",
      "\n",
      "Iteration 300, loss = 1.7287\n",
      "Checking accuracy on the val set\n",
      "Got 404 / 1000 correct (0.40%)\n",
      "\n",
      "Iteration 400, loss = 1.7200\n",
      "Checking accuracy on the val set\n",
      "Got 445 / 1000 correct (0.45%)\n",
      "\n",
      "Iteration 500, loss = 1.7015\n",
      "Checking accuracy on the val set\n",
      "Got 459 / 1000 correct (0.46%)\n",
      "\n",
      "Iteration 600, loss = 1.6525\n",
      "Checking accuracy on the val set\n",
      "Got 469 / 1000 correct (0.47%)\n",
      "\n",
      "Iteration 700, loss = 1.7230\n",
      "Checking accuracy on the val set\n",
      "Got 472 / 1000 correct (0.47%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "conv_w1 = random_weight((channel_1, 3, 5, 5))\n",
    "conv_b1 = zero_weight(channel_1)\n",
    "conv_w2 = random_weight((channel_2, channel_1, 3, 3))\n",
    "conv_b2 = zero_weight(channel_2)\n",
    "fc_w = random_weight((channel_2 * 32 * 32, 10))\n",
    "fc_b = zero_weight(1)\n",
    "\n",
    "params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
    "train_part2(three_layer_convnet, params, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7893c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = flatten(x)\n",
    "        scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        return scores\n",
    "    \n",
    "def test_TwoLayerFC():\n",
    "    input_size = 50\n",
    "    x = torch.zeros((64, input_size), dtype=dtype)\n",
    "    model = TwoLayerFC(input_size, 42, 10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())\n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54ca208f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, channel_1, 5, padding=2, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        self.conv2 = nn.Conv2d(channel_1, channel_2, 3, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        self.fc = nn.Linear(channel_2 * 32 * 32, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = flatten(x)\n",
    "        scores = self.fc(x)\n",
    "        return scores\n",
    "    \n",
    "def test_ThreeLayerConvNet():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)\n",
    "    model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea0ed969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds==y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d03421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "\n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b628db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.4179\n",
      "Checking accuracy on validation set\n",
      "Got 156 / 1000 correct (15.60)\n",
      "\n",
      "Iteration 100, loss = 2.0242\n",
      "Checking accuracy on validation set\n",
      "Got 395 / 1000 correct (39.50)\n",
      "\n",
      "Iteration 200, loss = 1.6251\n",
      "Checking accuracy on validation set\n",
      "Got 390 / 1000 correct (39.00)\n",
      "\n",
      "Iteration 300, loss = 1.9791\n",
      "Checking accuracy on validation set\n",
      "Got 343 / 1000 correct (34.30)\n",
      "\n",
      "Iteration 400, loss = 1.9126\n",
      "Checking accuracy on validation set\n",
      "Got 425 / 1000 correct (42.50)\n",
      "\n",
      "Iteration 500, loss = 1.9340\n",
      "Checking accuracy on validation set\n",
      "Got 414 / 1000 correct (41.40)\n",
      "\n",
      "Iteration 600, loss = 1.9275\n",
      "Checking accuracy on validation set\n",
      "Got 402 / 1000 correct (40.20)\n",
      "\n",
      "Iteration 700, loss = 2.1010\n",
      "Checking accuracy on validation set\n",
      "Got 448 / 1000 correct (44.80)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "model = TwoLayerFC(3 * 32 * 32, hidden_layer_size, 10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a309e437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.2246\n",
      "Checking accuracy on validation set\n",
      "Got 76 / 1000 correct (7.60)\n",
      "\n",
      "Iteration 100, loss = 2.0094\n",
      "Checking accuracy on validation set\n",
      "Got 374 / 1000 correct (37.40)\n",
      "\n",
      "Iteration 200, loss = 1.5607\n",
      "Checking accuracy on validation set\n",
      "Got 399 / 1000 correct (39.90)\n",
      "\n",
      "Iteration 300, loss = 1.6306\n",
      "Checking accuracy on validation set\n",
      "Got 419 / 1000 correct (41.90)\n",
      "\n",
      "Iteration 400, loss = 1.6600\n",
      "Checking accuracy on validation set\n",
      "Got 452 / 1000 correct (45.20)\n",
      "\n",
      "Iteration 500, loss = 1.7936\n",
      "Checking accuracy on validation set\n",
      "Got 472 / 1000 correct (47.20)\n",
      "\n",
      "Iteration 600, loss = 1.6498\n",
      "Checking accuracy on validation set\n",
      "Got 477 / 1000 correct (47.70)\n",
      "\n",
      "Iteration 700, loss = 1.7103\n",
      "Checking accuracy on validation set\n",
      "Got 491 / 1000 correct (49.10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "model = ThreeLayerConvNet(3, channel_1, channel_2, 10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fab52d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3573\n",
      "Checking accuracy on validation set\n",
      "Got 136 / 1000 correct (13.60)\n",
      "\n",
      "Iteration 100, loss = 1.7764\n",
      "Checking accuracy on validation set\n",
      "Got 403 / 1000 correct (40.30)\n",
      "\n",
      "Iteration 200, loss = 1.3513\n",
      "Checking accuracy on validation set\n",
      "Got 435 / 1000 correct (43.50)\n",
      "\n",
      "Iteration 300, loss = 1.6495\n",
      "Checking accuracy on validation set\n",
      "Got 403 / 1000 correct (40.30)\n",
      "\n",
      "Iteration 400, loss = 1.8281\n",
      "Checking accuracy on validation set\n",
      "Got 427 / 1000 correct (42.70)\n",
      "\n",
      "Iteration 500, loss = 1.7685\n",
      "Checking accuracy on validation set\n",
      "Got 429 / 1000 correct (42.90)\n",
      "\n",
      "Iteration 600, loss = 2.1002\n",
      "Checking accuracy on validation set\n",
      "Got 445 / 1000 correct (44.50)\n",
      "\n",
      "Iteration 700, loss = 1.7316\n",
      "Checking accuracy on validation set\n",
      "Got 430 / 1000 correct (43.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "    \n",
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size, 10),\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "269a8262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3111\n",
      "Checking accuracy on validation set\n",
      "Got 81 / 1000 correct (8.10)\n",
      "\n",
      "Iteration 100, loss = 1.6125\n",
      "Checking accuracy on validation set\n",
      "Got 472 / 1000 correct (47.20)\n",
      "\n",
      "Iteration 200, loss = 1.2376\n",
      "Checking accuracy on validation set\n",
      "Got 521 / 1000 correct (52.10)\n",
      "\n",
      "Iteration 300, loss = 1.4588\n",
      "Checking accuracy on validation set\n",
      "Got 497 / 1000 correct (49.70)\n",
      "\n",
      "Iteration 400, loss = 1.2304\n",
      "Checking accuracy on validation set\n",
      "Got 524 / 1000 correct (52.40)\n",
      "\n",
      "Iteration 500, loss = 1.4531\n",
      "Checking accuracy on validation set\n",
      "Got 522 / 1000 correct (52.20)\n",
      "\n",
      "Iteration 600, loss = 1.5504\n",
      "Checking accuracy on validation set\n",
      "Got 560 / 1000 correct (56.00)\n",
      "\n",
      "Iteration 700, loss = 1.2581\n",
      "Checking accuracy on validation set\n",
      "Got 584 / 1000 correct (58.40)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, channel_1, 5, padding=2, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_1, channel_2, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2*32*32, 10)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                    momentum=0.9, nesterov=True)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02826a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
